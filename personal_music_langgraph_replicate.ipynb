{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc6a60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d072e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ok: True\n",
      "REPLICATE ok: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "\n",
    "import os\n",
    "print(\"OPENAI ok:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"REPLICATE ok:\", bool(os.getenv(\"REPLICATE_API_TOKEN\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ed431b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'replicate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlanggraph\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgraph\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StateGraph, START, END\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreplicate\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m urlparse\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'replicate'"
     ]
    }
   ],
   "source": [
    "# 기본 임포트\n",
    "from typing import List, Dict, Literal, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "import time, os, requests\n",
    "import replicate\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 스키마 정의 (EmotionResult / MusicBrief / GraphState)\n",
    "Valence = Annotated[float, Field(ge=-1.0, le=1.0)]\n",
    "Arousal = Annotated[float, Field(ge=0.0, le=1.0)]\n",
    "BPM     = Annotated[int,   Field(ge=50,  le=140)]\n",
    "DurSec  = Annotated[int,   Field(ge=60,   le=90)] # 음악 재생시간(60초 ~ 90초)\n",
    "\n",
    "class EmotionResult(BaseModel):\n",
    "    primary: str\n",
    "    valence: Valence = 0.0\n",
    "    arousal: Arousal = 0.5\n",
    "    confidence: Arousal = 0.7\n",
    "    reasons: str = \"—\"\n",
    "\n",
    "class MusicBrief(BaseModel):\n",
    "    mood: str\n",
    "    bpm: BPM = 90\n",
    "    key: str\n",
    "    duration_sec: DurSec = 60               # 음악 기본 재생시간 60초\n",
    "    instruments: List[str] = []\n",
    "    style_tags: List[str] = []\n",
    "    prompt: str  # 영어 프롬프트\n",
    "\n",
    "class GraphState(TypedDict, total=False):\n",
    "    user_text: str\n",
    "    emotion: EmotionResult\n",
    "    brief: MusicBrief\n",
    "    audio_path: str\n",
    "    provider_used: Literal[\"replicate\"]\n",
    "    meta: Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4057eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) LLM 헬퍼 (OpenAI)\n",
    "def get_llm():\n",
    "    # 스키마 맞춤 출력이 중요 → 낮은 temperature\n",
    "    return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36626a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 감정 분석 노드\n",
    "def analyze_emotion_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm()\n",
    "    sys = (\n",
    "        \"당신은 심리 정서를 요약하는 분석가입니다. \"\n",
    "        \"사용자 텍스트에서 주요 감정을 한 단어(또는 짧은 구)로 도출하고, \"\n",
    "        \"valence(-1~1), arousal(0~1), confidence(0~1)을 추정하세요. \"\n",
    "        \"사용자 텍스트는 서술형일 수 있으며 직접적 요청이 없을 수 있다. \"\n",
    "        \"장면·행동·몸의 단서만으로 valence/arousal을 추정하라.\"\n",
    "        \"반드시 EmotionResult(JSON 스키마)에 맞춰 응답하세요.\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(EmotionResult)\n",
    "    result = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":state[\"user_text\"]}\n",
    "    ])\n",
    "    state[\"emotion\"] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 음악 브리프 노드\n",
    "def compose_brief_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm()\n",
    "    emo: EmotionResult = state[\"emotion\"]\n",
    "    sys = (\n",
    "    \"너는 음악 감독이다. 아래 감정 분석과 사용자 텍스트를 참고해 \"\n",
    "    \"개인의 감정과 스토리를 반영한, 예술치료/심리 안정 목적의 짧은 BGM을 위한 \"\n",
    "    \"Music Brief를 JSON으로 만들어라.\\n\"\n",
    "    \"\\n\"\n",
    "    \"## 치료적 목표(필수)\\n\"\n",
    "    \"- 사용자의 현재 상태를 '공조절(co-regulation)' 관점에서 보정한다.\\n\"\n",
    "    \"- 정서 조절 전략(regulation_mode)을 다음에서 고른다: \"\n",
    "    \"  soothe(불안·고각성 완화), uplift(우울·저각성 부드럽게 상승), \"\n",
    "    \"  sustain(편안한 긍정 유지), ground(과도한 긍정/흥분을 안정적으로 접지).\\n\"\n",
    "    \"- 선택한 전략은 style_tags에 'regulate:<mode>' 형태로 반드시 포함한다.\\n\"\n",
    "    \"\\n\"\n",
    "    \"## 파라미터 규칙\\n\"\n",
    "    \"1) bpm: 50~140 중 선택하되, duration_sec은 60~90으로 제한한다.\\n\"\n",
    "    \"   - arousal↑ → bpm↑ 경향. 단, soothe/ground 전략일 때는 중간 템포(70~100)로 과자극 방지.\\n\"\n",
    "    \"   - uplift 전략(저각성·우울)일 땐 72~90 범위에서 부드럽게 추진.\\n\"\n",
    "    \"2) duration_sec: 60~90. 불안(arousal>0.6) 또는 우울(valence<-0.2)은 78~90을 우선 고려.\\n\"\n",
    "    \"3) key: valence>=0.2 → 메이저(C/G/F/D 등), valence<=-0.2 → 마이너(A/D/E/B 등), \"\n",
    "    \"   중립은 혼합 가능. 동일 키('C major')만 반복 사용 금지.\\n\"\n",
    "    \"4) instruments: 2~4개. 기본은 warm piano, soft pad.\\n\"\n",
    "    \"   - soothe/ground: light percussion는 있어도 아주 절제(brush, soft tick 등), 하이햇/킥 과도 금지.\\n\"\n",
    "    \"   - uplift: strings(legato)나 gentle pulse로 미세한 전진감.\\n\"\n",
    "    \"5) style_tags: 3~6개. 예: calming, minimal, warm, ambient, breathing, focus, regulate:<mode>.\\n\"\n",
    "    \"6) 구조(권장): 60~90초 안에 intro(짧은 페이드인, 4bar) → body(점진적 레이어, 8~12bar) → \"\n",
    "    \"   outro(2~4bar, 2~3초 페이드아웃). 루프 안전(loop-safe) 문장감 유지.\\n\"\n",
    "    \"7) 안전 가드: 과도한 트랜지언트/왜곡/사이드체인 펌핑/금속성 심벌/저역 과출력 금지. \"\n",
    "    \"   다이내믹은 soft~medium.\\n\"\n",
    "    \"8) prompt: 영어 한 문장, 18~25단어. 악기·무드·질감·다이내믹을 서술하되 숫자(BPM/key/duration) 금지. \"\n",
    "    \"   사용자의 텍스트에서 핵심 단어 1~2개를 분위기 단서로 녹여라(직역 금지, 뉘앙스만 반영).\\n\"\n",
    "    \"9) JSON만 출력. 추가 설명 금지.\\n\"\n",
    "    \"사용자 텍스트에 요청이 없어도 valence/arousal로 regulation_mode(soothe/uplift/sustain/ground)를 결정하고 \"\n",
    "    \"style_tags에 'regulate:<mode>'를 포함하라.\"\n",
    ")\n",
    "\n",
    "    usr = (\n",
    "        f\"# Emotion\\nprimary={emo.primary}, valence={emo.valence}, \"\n",
    "        f\"arousal={emo.arousal}, confidence={emo.confidence}\\n\\n\"\n",
    "        f\"# Text\\n{state['user_text']}\\n\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(MusicBrief)\n",
    "    brief = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":usr}\n",
    "    ])\n",
    "\n",
    "# ▼ duration 보정 (60~90초로 강제)\n",
    "    if brief.duration_sec < 60:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 60})\n",
    "    elif brief.duration_sec > 90:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 90})\n",
    "\n",
    "    state[\"brief\"] = brief\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd8cb784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 5) Replicate(Stable Audio 2.5) 호출 함수\n",
    "\n",
    "MODEL_ID = \"stability-ai/stable-audio-2.5:46a2601577d0e31aa99b03c9d7fd2142fa3b96a282338758f794b620e35c75b7\"\n",
    "\n",
    "def generate_with_replicate_strict(prompt: str, duration: int) -> str:\n",
    "    tok = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "    assert tok, \"REPLICATE_API_TOKEN이 없습니다 (.env 확인)\"\n",
    "    assert 60 <= int(duration) <= 90, f\"duration(초)은 60~90 범위여야 합니다: {duration}\"\n",
    "\n",
    "    # 최신 클라: FileOutput 반환하는 경우가 많음\n",
    "    out = replicate.run(MODEL_ID, input={\"prompt\": prompt, \"duration\": int(duration)})\n",
    "    first = out[0] if isinstance(out, (list, tuple)) else out\n",
    "\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    ts = int(time.time())\n",
    "\n",
    "    # FileOutput (권장 경로)\n",
    "    if hasattr(first, \"read\"):\n",
    "        ext = \".bin\"\n",
    "        url_attr = getattr(first, \"url\", None)\n",
    "        if isinstance(url_attr, str):\n",
    "            ext_candidate = os.path.splitext(urlparse(url_attr).path)[1].lower()\n",
    "            if ext_candidate:\n",
    "                ext = ext_candidate\n",
    "        out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(first.read())\n",
    "        return out_path\n",
    "\n",
    "    # 문자열 URL 경로\n",
    "    if isinstance(first, str):\n",
    "        r = requests.get(first, timeout=120); r.raise_for_status()\n",
    "        ct = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        if \"wav\" in ct: ext = \".wav\"\n",
    "        elif \"mpeg\" in ct or \"mp3\" in ct: ext = \".mp3\"\n",
    "        else: ext = os.path.splitext(urlparse(first).path)[1] or \".bin\"\n",
    "        out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        return out_path\n",
    "\n",
    "    # dict 경로 (드물게)\n",
    "    if isinstance(first, dict):\n",
    "        url = first.get(\"url\") or first.get(\"audio\") or first.get(\"output\")\n",
    "        if isinstance(url, str):\n",
    "            r = requests.get(url, timeout=120); r.raise_for_status()\n",
    "            ext = os.path.splitext(urlparse(url).path)[1] or \".bin\"\n",
    "            out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            return out_path\n",
    "\n",
    "    raise RuntimeError(f\"Unexpected replicate output type: {type(first)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eebb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 음악 생성 노드 (Replicate만)\n",
    "def generate_music_node(state: GraphState) -> GraphState:\n",
    "    brief: MusicBrief = state[\"brief\"]\n",
    "    path = generate_with_replicate_strict(brief.prompt, int(brief.duration_sec))\n",
    "\n",
    "    state[\"audio_path\"] = path\n",
    "    state[\"provider_used\"] = \"replicate\"\n",
    "    state[\"meta\"] = {\n",
    "        \"emotion\": state[\"emotion\"].model_dump(),\n",
    "        \"brief\": state[\"brief\"].model_dump(),\n",
    "        \"provider\": \"replicate\",\n",
    "        \"path\": path,\n",
    "    }\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"analyze_emotion\", analyze_emotion_node)\n",
    "workflow.add_node(\"compose_brief\",  compose_brief_node)\n",
    "workflow.add_node(\"generate_music\", generate_music_node)\n",
    "\n",
    "workflow.add_edge(START, \"analyze_emotion\")\n",
    "workflow.add_edge(\"analyze_emotion\", \"compose_brief\")\n",
    "workflow.add_edge(\"compose_brief\",  \"generate_music\")\n",
    "workflow.add_edge(\"generate_music\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f17a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'replicate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m state = {\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33muser_text\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m일정을 정리하다가 페이지를 넘기는 손이 자주 멈췄다. 시간이 흐르는 게 잘 느껴지지 않았다.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m final = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=== Emotion ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(final[\u001b[33m\"\u001b[39m\u001b[33memotion\u001b[39m\u001b[33m\"\u001b[39m].model_dump())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1560\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[39m\n\u001b[32m   1558\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1559\u001b[39m     chunks = []\n\u001b[32m-> \u001b[39m\u001b[32m1560\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1561\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1562\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1565\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1568\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1569\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1570\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   1571\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlatest\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1298\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1287\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1288\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   1289\u001b[39m     \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1290\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1291\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(\n\u001b[32m   1293\u001b[39m         input_keys=\u001b[38;5;28mself\u001b[39m.input_channels,\n\u001b[32m   1294\u001b[39m         interrupt_before=interrupt_before_,\n\u001b[32m   1295\u001b[39m         interrupt_after=interrupt_after_,\n\u001b[32m   1296\u001b[39m         manager=run_manager,\n\u001b[32m   1297\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1299\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1300\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1301\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1302\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1303\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1304\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   1305\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1306\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\pregel\\runner.py:56\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m     54\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\pregel\\retry.py:29\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy)\u001b[39m\n\u001b[32m     27\u001b[39m task.writes.clear()\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py:409\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m context.run(_set_config_context, config)\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    411\u001b[39m     \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\hyun soo kim\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langgraph-env-e8JFwEVd-py3.11\\Lib\\site-packages\\langgraph\\utils\\runnable.py:183\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    182\u001b[39m     context.run(_set_config_context, config)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m     ret = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mgenerate_music_node\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_music_node\u001b[39m(state: GraphState) -> GraphState:\n\u001b[32m      3\u001b[39m     brief: MusicBrief = state[\u001b[33m\"\u001b[39m\u001b[33mbrief\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     path = \u001b[43mgenerate_with_replicate_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbrief\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbrief\u001b[49m\u001b[43m.\u001b[49m\u001b[43mduration_sec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33maudio_path\u001b[39m\u001b[33m\"\u001b[39m] = path\n\u001b[32m      7\u001b[39m     state[\u001b[33m\"\u001b[39m\u001b[33mprovider_used\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mreplicate\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mgenerate_with_replicate_strict\u001b[39m\u001b[34m(prompt, duration)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[32m60\u001b[39m <= \u001b[38;5;28mint\u001b[39m(duration) <= \u001b[32m90\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mduration(초)은 60~90 범위여야 합니다: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# 최신 클라이언트는 기본적으로 FileOutput을 반환\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m out = \u001b[43mreplicate\u001b[49m.run(MODEL_ID, \u001b[38;5;28minput\u001b[39m={\u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m: prompt, \u001b[33m\"\u001b[39m\u001b[33mduration\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(duration)})\n\u001b[32m     12\u001b[39m first = out[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[32m     14\u001b[39m os.makedirs(\u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'replicate' is not defined"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"user_text\": \"일정을 정리하다가 페이지를 넘기는 손이 자주 멈췄다. 시간이 흐르는 게 잘 느껴지지 않았다.\"\n",
    "}\n",
    "final = graph.invoke(state)\n",
    "\n",
    "print(\"=== Emotion ===\")\n",
    "print(final[\"emotion\"].model_dump())\n",
    "print(\"\\n=== Music Brief ===\")\n",
    "print(final[\"brief\"].model_dump())\n",
    "print(\"\\n=== Provider Used ===\")\n",
    "print(final[\"provider_used\"])\n",
    "print(\"\\n=== Audio Path ===\")\n",
    "print(final[\"audio_path\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env-e8JFwEVd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
