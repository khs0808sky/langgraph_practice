{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dc6a60bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d072e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ok: True\n",
      "REPLICATE ok: True\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "\n",
    "import os\n",
    "print(\"OPENAI ok:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"REPLICATE ok:\", bool(os.getenv(\"REPLICATE_API_TOKEN\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ed431b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 임포트\n",
    "from typing import List, Dict, Literal, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debf9c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) 스키마 정의 (EmotionResult / MusicBrief / GraphState)\n",
    "Valence = Annotated[float, Field(ge=-1.0, le=1.0)]\n",
    "Arousal = Annotated[float, Field(ge=0.0, le=1.0)]\n",
    "BPM     = Annotated[int,   Field(ge=50,  le=140)]\n",
    "DurSec  = Annotated[int,   Field(ge=30,   le=90)] # 음악 재생시간(30초 ~ 90초)\n",
    "\n",
    "class EmotionResult(BaseModel):\n",
    "    primary: str\n",
    "    valence: Valence = 0.0\n",
    "    arousal: Arousal = 0.5\n",
    "    confidence: Arousal = 0.7\n",
    "    reasons: str = \"—\"\n",
    "\n",
    "class MusicBrief(BaseModel):\n",
    "    mood: str\n",
    "    bpm: BPM = 90\n",
    "    key: str = \"C major\"\n",
    "    duration_sec: DurSec = 60               # 음악 기본 재생시간 60초\n",
    "    instruments: List[str] = []\n",
    "    style_tags: List[str] = []\n",
    "    prompt: str  # 영어 프롬프트\n",
    "\n",
    "class GraphState(TypedDict, total=False):\n",
    "    user_text: str\n",
    "    emotion: EmotionResult\n",
    "    brief: MusicBrief\n",
    "    audio_path: str\n",
    "    provider_used: Literal[\"replicate\"]\n",
    "    meta: Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f4057eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) LLM 헬퍼 (OpenAI)\n",
    "def get_llm():\n",
    "    # 스키마 맞춤 출력이 중요 → 낮은 temperature\n",
    "    return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "36626a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) 감정 분석 노드\n",
    "def analyze_emotion_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm()\n",
    "    sys = (\n",
    "        \"당신은 심리 정서를 요약하는 분석가입니다. \"\n",
    "        \"사용자 텍스트에서 주요 감정을 한 단어(또는 짧은 구)로 도출하고, \"\n",
    "        \"valence(-1~1), arousal(0~1), confidence(0~1)을 추정하세요. \"\n",
    "        \"반드시 EmotionResult(JSON 스키마)에 맞춰 응답하세요.\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(EmotionResult)\n",
    "    result = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":state[\"user_text\"]}\n",
    "    ])\n",
    "    state[\"emotion\"] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c3ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) 음악 브리프 노드\n",
    "def compose_brief_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm()\n",
    "    emo: EmotionResult = state[\"emotion\"]\n",
    "    sys = (\n",
    "        \"너는 음악 감독이다. 아래 감정 분석과 사용자 텍스트를 참고해 \"\n",
    "        \"치유/안정 목적의 짧은 BGM을 위한 Music Brief를 JSON으로 만들어라. \"\n",
    "        \"bpm=50~140, duration_sec=30~90, key는 'C major' 같은 형식. \"\n",
    "        \"prompt는 영어로 핵심 악기/무드/다이내믹을 간결히 포함.\"\n",
    "    )\n",
    "    usr = (\n",
    "        f\"# Emotion\\nprimary={emo.primary}, valence={emo.valence}, \"\n",
    "        f\"arousal={emo.arousal}, confidence={emo.confidence}\\n\\n\"\n",
    "        f\"# Text\\n{state['user_text']}\\n\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(MusicBrief)\n",
    "    brief = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":usr}\n",
    "    ])\n",
    "\n",
    "# ▼ duration 보정 (30~90초로 강제)\n",
    "    if brief.duration_sec < 30:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 30})\n",
    "    elif brief.duration_sec > 90:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 90})\n",
    "\n",
    "    state[\"brief\"] = brief\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01898d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Replicate(Stable Audio 2.5) 호출 함수\n",
    "import time, tempfile, requests, soundfile as sf, os, numpy as np\n",
    "import replicate\n",
    "\n",
    "# 모델 버전은 바뀔 수 있음 — 404 나오면 Replicate 모델 페이지에서 최신 버전ID로 교체\n",
    "MODEL_ID = \"stability-ai/stable-audio-2.5:46a2601577d0e31aa99b03c9d7fd2142fa3b96a282338758f794b620e35c75b7\"\n",
    "\n",
    "def generate_with_replicate_strict(prompt: str, duration: int) -> str:\n",
    "    tok = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "    assert tok, \"REPLICATE_API_TOKEN이 없습니다 (.env 확인)\"\n",
    "    assert 30 <= int(duration) <= 90, f\"duration(초)은 30~90 범위여야 합니다: {duration}\"\n",
    "\n",
    "    # 1) 모델 실행\n",
    "    urls = replicate.run(MODEL_ID, input={\"prompt\": prompt, \"duration\": int(duration)})\n",
    "    if not (isinstance(urls, list) and urls):\n",
    "        raise RuntimeError(f\"Replicate 결과 비어있음: {urls}\")\n",
    "\n",
    "    # 2) 결과 파일 다운로드 → 포맷 자동 감지 후 모노 WAV 저장\n",
    "    url = urls[0]\n",
    "    r = requests.get(url, timeout=120); r.raise_for_status()\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(suffix=\".bin\", delete=True) as tmp:\n",
    "        tmp.write(r.content); tmp.flush()\n",
    "        data, sr = sf.read(tmp.name)     # mp3/wav 자동\n",
    "        if data.ndim > 1:\n",
    "            data = data.mean(axis=1).astype(\"float32\")\n",
    "\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    out_path = f\"outputs/stableaudio_{int(time.time())}.wav\"\n",
    "    sf.write(out_path, data, sr)\n",
    "    return out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a8eebb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) 음악 생성 노드 (Replicate만)\n",
    "def generate_music_node(state: GraphState) -> GraphState:\n",
    "    brief: MusicBrief = state[\"brief\"]\n",
    "    path = generate_with_replicate_strict(brief.prompt, int(brief.duration_sec))\n",
    "\n",
    "    state[\"audio_path\"] = path\n",
    "    state[\"provider_used\"] = \"replicate\"\n",
    "    state[\"meta\"] = {\n",
    "        \"emotion\": state[\"emotion\"].model_dump(),\n",
    "        \"brief\": state[\"brief\"].model_dump(),\n",
    "        \"provider\": \"replicate\",\n",
    "        \"path\": path,\n",
    "    }\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "48258f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRY_RUN: 1\n"
     ]
    }
   ],
   "source": [
    "# 임시) 분기 함수 추가 (credit문제로 인해\n",
    "def should_generate(state: GraphState) -> str:\n",
    "    # DRY_RUN=1 이거나 REPLICATE_API_TOKEN 없으면 건너뜀\n",
    "    dry = os.getenv(\"DRY_RUN\", \"0\") == \"1\"\n",
    "    has_repl = bool(os.getenv(\"REPLICATE_API_TOKEN\"))\n",
    "    return \"go\" if (not dry and has_repl) else \"skip\"\n",
    "\n",
    "# 임시\n",
    "os.environ[\"DRY_RUN\"] = \"1\"\n",
    "print(\"DRY_RUN:\", os.getenv(\"DRY_RUN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "344a40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"analyze_emotion\", analyze_emotion_node)\n",
    "workflow.add_node(\"compose_brief\",  compose_brief_node)\n",
    "workflow.add_node(\"generate_music\", generate_music_node)\n",
    "\n",
    "workflow.add_edge(START, \"analyze_emotion\")\n",
    "workflow.add_edge(\"analyze_emotion\", \"compose_brief\")\n",
    "# workflow.add_edge(\"compose_brief\",  \"generate_music\")\n",
    "# workflow.add_edge(\"generate_music\", END)\n",
    "\n",
    "#임시\n",
    "workflow.add_conditional_edges(\n",
    "    \"compose_brief\",\n",
    "    should_generate,\n",
    "    {\"go\": \"generate_music\", \"skip\": END}\n",
    ")\n",
    "workflow.add_edge(\"generate_music\", END)\n",
    "\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4832f17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Emotion ===\n",
      "{'primary': '불안', 'valence': -0.5, 'arousal': 0.7, 'confidence': 0.8, 'reasons': '발표를 앞두고 불안함을 느끼고 있지만, 차분해지고 싶다는 의지가 나타나고 있어 감정의 복합성이 존재함.'}\n",
      "\n",
      "=== Music Brief ===\n",
      "{'mood': 'Calm', 'bpm': 70, 'key': 'C major', 'duration_sec': 30, 'instruments': ['Piano', 'Strings', 'Flute'], 'style_tags': ['Ambient', 'Relaxing', 'Meditative'], 'prompt': 'A soothing piano melody with soft strings and gentle flute, creating a calm atmosphere to ease anxiety before a presentation.'}\n",
      "\n",
      "=== Provider Used ===\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'provider_used'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(final[\u001b[33m\"\u001b[39m\u001b[33mbrief\u001b[39m\u001b[33m\"\u001b[39m].model_dump())\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Provider Used ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfinal\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprovider_used\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Audio Path ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(final[\u001b[33m\"\u001b[39m\u001b[33maudio_path\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[31mKeyError\u001b[39m: 'provider_used'"
     ]
    }
   ],
   "source": [
    "state = {\n",
    "    \"user_text\": \"오늘 중요한 발표를 앞두고 불안하지만 차분해지고 싶어요.\"\n",
    "}\n",
    "final = graph.invoke(state)\n",
    "\n",
    "print(\"=== Emotion ===\")\n",
    "print(final[\"emotion\"].model_dump())\n",
    "print(\"\\n=== Music Brief ===\")\n",
    "print(final[\"brief\"].model_dump())\n",
    "# print(\"\\n=== Provider Used ===\")\n",
    "# print(final[\"provider_used\"])\n",
    "# print(\"\\n=== Audio Path ===\")\n",
    "# print(final[\"audio_path\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
