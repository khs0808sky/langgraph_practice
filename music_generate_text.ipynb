{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "501c2c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI ok: True\n",
      "REPLICATE ok: True\n",
      "USE_REPLICATE: 0\n"
     ]
    }
   ],
   "source": [
    "# === 0) 환경 로드 ===\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv(usecwd=True), override=True)\n",
    "\n",
    "import os, time, requests\n",
    "print(\"OPENAI ok:\", bool(os.getenv(\"OPENAI_API_KEY\")))\n",
    "print(\"REPLICATE ok:\", bool(os.getenv(\"REPLICATE_API_TOKEN\")))\n",
    "print(\"USE_REPLICATE:\", os.getenv(\"USE_REPLICATE\"))  # \"1\"일 때만 실제 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ccc30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1) 기본 임포트/스키마 ===\n",
    "from typing import List, Dict, Literal, TypedDict\n",
    "from pydantic import BaseModel, Field\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "# replicate는 \"선택 임포트\"\n",
    "try:\n",
    "    import replicate  # 있으면 사용\n",
    "    _HAVE_REPLICATE = True\n",
    "except ModuleNotFoundError:\n",
    "    replicate = None\n",
    "    _HAVE_REPLICATE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e3c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "Valence = Annotated[float, Field(ge=-1.0, le=1.0)]\n",
    "Arousal = Annotated[float, Field(ge=0.0, le=1.0)]\n",
    "BPM     = Annotated[int,   Field(ge=50,  le=140)]\n",
    "DurSec  = Annotated[int,   Field(ge=120,  le=180)]  # 120~180초\n",
    "\n",
    "class EmotionResult(BaseModel):\n",
    "    primary: str\n",
    "    valence: Valence = 0.0\n",
    "    arousal: Arousal = 0.5\n",
    "    confidence: Arousal = 0.7\n",
    "    reasons: str = \"—\"\n",
    "\n",
    "class MusicBrief(BaseModel):\n",
    "    mood: str\n",
    "    bpm: BPM = 90\n",
    "    key: str\n",
    "    duration_sec: DurSec = 120\n",
    "    instruments: List[str] = []\n",
    "    style_tags: List[str] = []\n",
    "    prompt: str  # 영어 프롬프트\n",
    "\n",
    "class GraphState(TypedDict, total=False):\n",
    "    user_text: str\n",
    "    emotion: EmotionResult\n",
    "    brief: MusicBrief\n",
    "    audio_path: str\n",
    "    provider_used: Literal[\"replicate\",\"rest\",\"skipped\"]\n",
    "    meta: Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405e5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2) LLM 헬퍼 ===\n",
    "def get_llm(temp=0.2):\n",
    "    return ChatOpenAI(model=\"gpt-4o-mini\", temperature=temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "847d2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 3) 감정 분석 노드 ===\n",
    "def analyze_emotion_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm(0.2)\n",
    "    sys = (\n",
    "        \"당신은 심리 정서를 요약하는 분석가입니다. \"\n",
    "        \"사용자 텍스트에서 주요 감정을 한 단어(또는 짧은 구)로 도출하고, \"\n",
    "        \"valence(-1~1), arousal(0~1), confidence(0~1)을 추정하세요. \"\n",
    "        \"사용자 텍스트는 서술형일 수 있으며 직접적 요청이 없을 수 있다. \"\n",
    "        \"장면·행동·몸의 단서만으로 valence/arousal을 추정하라.\\n\"\n",
    "        \"반드시 EmotionResult(JSON 스키마)에 맞춰 응답하세요.\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(EmotionResult)\n",
    "    result = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":state[\"user_text\"]}\n",
    "    ])\n",
    "    state[\"emotion\"] = result\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5077d87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 4) 음악 브리프 노드 ===\n",
    "def compose_brief_node(state: GraphState) -> GraphState:\n",
    "    llm = get_llm(0.6)  # 브리프 다양성 조금 ↑\n",
    "    emo: EmotionResult = state[\"emotion\"]\n",
    "    sys = (\n",
    "        \"너는 음악 감독이다. 아래 감정 분석과 사용자 텍스트를 참고해 \"\n",
    "        \"개인의 감정과 스토리를 반영한, 예술치료/심리 안정 목적의 짧은 BGM을 위한 \"\n",
    "        \"Music Brief를 JSON으로 만들어라.\\n\\n\"\n",
    "        \"## 치료적 목표(필수)\\n\"\n",
    "        \"- 사용자의 현재 상태를 '공조절(co-regulation)' 관점에서 보정한다.\\n\"\n",
    "        \"- 정서 조절 전략(regulation_mode)을 다음에서 고른다: \"\n",
    "        \"  soothe(불안·고각성 완화), uplift(우울·저각성 부드럽게 상승), \"\n",
    "        \"  sustain(편안한 긍정 유지), ground(과도한 긍정/흥분을 안정적으로 접지).\\n\"\n",
    "        \"- 선택한 전략은 style_tags에 'regulate:<mode>' 형태로 반드시 포함한다.\\n\\n\"\n",
    "        \"## 파라미터 규칙\\n\"\n",
    "        \"1) bpm: 50~140 중 선택하되, duration_sec은 60~90으로 제한한다.\\n\"\n",
    "        \"   - arousal↑ → bpm↑ 경향. 단, soothe/ground 전략일 때는 중간 템포(70~100)로 과자극 방지.\\n\"\n",
    "        \"   - uplift 전략(저각성·우울)일 땐 72~90 범위에서 부드럽게 추진.\\n\"\n",
    "        \"2) duration_sec: 120~180. 불안(arousal>0.6) 또는 우울(valence<-0.2)은 150~180을 우선 고려.\\n\"\n",
    "        \"3) key: valence>=0.2 → 메이저(C/G/F/D 등), valence<=-0.2 → 마이너(A/D/E/B 등), \"\n",
    "        \"   중립은 혼합 가능. 동일 키('C major')만 반복 사용 금지.\\n\"\n",
    "        \"4) instruments: 2~4개. 기본은 warm piano, soft pad.\\n\"\n",
    "        \"   - soothe/ground: light percussion는 있어도 아주 절제(brush, soft tick 등), 하이햇/킥 과도 금지.\\n\"\n",
    "        \"   - uplift: strings(legato)나 gentle pulse로 미세한 전진감.\\n\"\n",
    "        \"5) style_tags: 3~6개. 예: calming, minimal, warm, ambient, breathing, focus, regulate:<mode>.\\n\"\n",
    "        \"6) 구조(권장): 120~180초 안에 intro(짧은 페이드인, 4bar) → body(점진적 레이어, 8~12bar) → \"\n",
    "        \"   outro(2~4bar, 2~3초 페이드아웃). 루프 안전(loop-safe) 문장감 유지.\\n\"\n",
    "        \"7) 안전 가드: 과도한 트랜지언트/왜곡/사이드체인 펌핑/금속성 심벌/저역 과출력 금지. \"\n",
    "        \"   다이내믹은 soft~medium.\\n\"\n",
    "        \"8) prompt: 영어 한 문장, 18~25단어. 악기·무드·질감·다이내믹을 서술하되 숫자(BPM/key/duration) 금지. \"\n",
    "        \"   사용자의 텍스트에서 핵심 단어 1~2개를 분위기 단서로 녹여라(직역 금지, 뉘앙스만 반영).\\n\"\n",
    "        \"9) JSON만 출력. 추가 설명 금지.\\n\"\n",
    "        \"사용자 텍스트에 요청이 없어도 valence/arousal로 regulation_mode(soothe/uplift/sustain/ground)를 결정하고 \"\n",
    "        \"style_tags에 'regulate:<mode>'를 포함하라.\"\n",
    "    )\n",
    "\n",
    "    usr = (\n",
    "        f\"# Emotion\\nprimary={emo.primary}, valence={emo.valence}, \"\n",
    "        f\"arousal={emo.arousal}, confidence={emo.confidence}\\n\\n\"\n",
    "        f\"# Text\\n{state['user_text']}\\n\"\n",
    "    )\n",
    "    structured = llm.with_structured_output(MusicBrief)\n",
    "    brief = structured.invoke([\n",
    "        {\"role\":\"system\",\"content\":sys},\n",
    "        {\"role\":\"user\",\"content\":usr}\n",
    "    ])\n",
    "\n",
    "    # duration 보정 (120~180초로 강제)\n",
    "    if brief.duration_sec < 120:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 120})\n",
    "    elif brief.duration_sec > 180:\n",
    "        brief = brief.model_copy(update={\"duration_sec\": 180})\n",
    "\n",
    "    state[\"brief\"] = brief\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036da407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 5) Replicate 호출 유틸 (클라/REST 자동 폴백) ===\n",
    "MODEL_ID = \"stability-ai/stable-audio-2.5:46a2601577d0e31aa99b03c9d7fd2142fa3b96a282338758f794b620e35c75b7\"\n",
    "_MODEL_VERSION = MODEL_ID.split(\":\")[1]  # REST용 버전 해시\n",
    "\n",
    "def _replicate_run(input_payload: dict, token: str):\n",
    "    # 패키지 있으면 우선 사용\n",
    "    if _HAVE_REPLICATE:\n",
    "        return replicate.run(MODEL_ID, input=input_payload)\n",
    "    # 없으면 REST 폴백 (설치 불필요, 크레딧 정상 차감)\n",
    "    headers = {\"Authorization\": f\"Token {token}\", \"Content-Type\": \"application/json\"}\n",
    "    create = requests.post(\n",
    "        \"https://api.replicate.com/v1/predictions\",\n",
    "        headers=headers,\n",
    "        json={\"version\": _MODEL_VERSION, \"input\": input_payload},\n",
    "        timeout=30,\n",
    "    )\n",
    "    create.raise_for_status()\n",
    "    pred = create.json()\n",
    "    pid = pred[\"id\"]\n",
    "    while pred[\"status\"] not in (\"succeeded\", \"failed\", \"canceled\"):\n",
    "        time.sleep(2)\n",
    "        r = requests.get(f\"https://api.replicate.com/v1/predictions/{pid}\", headers=headers, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        pred = r.json()\n",
    "    if pred[\"status\"] != \"succeeded\":\n",
    "        raise RuntimeError(f\"Replicate failed: {pred['status']} / {pred.get('error')}\")\n",
    "    return pred[\"output\"]  # 보통 URL 리스트\n",
    "\n",
    "def _save_first_output_to_file(out) -> str:\n",
    "    \"\"\"Replicate 출력(any) → 파일 저장하고 경로 반환\"\"\"\n",
    "    first = out[0] if isinstance(out, (list, tuple)) else out\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    ts = int(time.time())\n",
    "\n",
    "    # FileOutput (replicate 패키지 경로)\n",
    "    if hasattr(first, \"read\"):\n",
    "        ext = \".bin\"\n",
    "        url_attr = getattr(first, \"url\", None)\n",
    "        if isinstance(url_attr, str):\n",
    "            ext_candidate = os.path.splitext(urlparse(url_attr).path)[1].lower()\n",
    "            if ext_candidate:\n",
    "                ext = ext_candidate\n",
    "        out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(first.read())\n",
    "        return out_path\n",
    "\n",
    "    # URL 문자열\n",
    "    if isinstance(first, str):\n",
    "        r = requests.get(first, timeout=120); r.raise_for_status()\n",
    "        ct = (r.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        if \"wav\" in ct:\n",
    "            ext = \".wav\"\n",
    "        elif \"mpeg\" in ct or \"mp3\" in ct:\n",
    "            ext = \".mp3\"\n",
    "        else:\n",
    "            ext = os.path.splitext(urlparse(first).path)[1] or \".bin\"\n",
    "        out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        return out_path\n",
    "\n",
    "    # dict 형태 (드묾)\n",
    "    if isinstance(first, dict):\n",
    "        url = first.get(\"url\") or first.get(\"audio\") or first.get(\"output\")\n",
    "        if isinstance(url, str):\n",
    "            r = requests.get(url, timeout=120); r.raise_for_status()\n",
    "            ext = os.path.splitext(urlparse(url).path)[1] or \".bin\"\n",
    "            out_path = f\"outputs/stableaudio_{ts}{ext}\"\n",
    "            with open(out_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            return out_path\n",
    "\n",
    "    raise RuntimeError(f\"Unexpected replicate output type: {type(first)}\")\n",
    "\n",
    "def generate_with_replicate_strict(prompt: str, duration: int) -> str:\n",
    "    tok = os.getenv(\"REPLICATE_API_TOKEN\")\n",
    "    assert tok, \"REPLICATE_API_TOKEN이 없습니다 (.env 확인)\"\n",
    "    assert 120 <= int(duration) <= 180, f\"duration(초)은 120~180 범위여야 합니다: {duration}\"\n",
    "    out = _replicate_run({\"prompt\": prompt, \"duration\": int(duration)}, tok)\n",
    "    return _save_first_output_to_file(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d19f44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 6) 생성 노드 ===\n",
    "def generate_music_node(state: GraphState) -> GraphState:\n",
    "    brief: MusicBrief = state[\"brief\"]\n",
    "    path = generate_with_replicate_strict(brief.prompt, int(brief.duration_sec))\n",
    "    state[\"audio_path\"] = path\n",
    "    state[\"provider_used\"] = \"replicate\" if _HAVE_REPLICATE else \"rest\"\n",
    "    state[\"meta\"] = {\n",
    "        \"emotion\": state[\"emotion\"].model_dump(),\n",
    "        \"brief\": state[\"brief\"].model_dump(),\n",
    "        \"provider\": state[\"provider_used\"],\n",
    "        \"path\": path,\n",
    "    }\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a12062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 7) 토글 분기: 기본은 스킵(크레딧 0), 원할 때만 생성 ===\n",
    "def should_generate(state: GraphState) -> str:\n",
    "    use_flag = os.getenv(\"USE_REPLICATE\", \"0\") == \"1\" or state.get(\"force_generate\") is True\n",
    "    has_token = bool(os.getenv(\"REPLICATE_API_TOKEN\"))\n",
    "    return \"go\" if (use_flag and has_token) else \"skip\"\n",
    "\n",
    "def mark_skipped(state: GraphState) -> GraphState:\n",
    "    state[\"provider_used\"] = \"skipped\"\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3717930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 8) 그래프 구성 ===\n",
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"analyze_emotion\", analyze_emotion_node)\n",
    "workflow.add_node(\"compose_brief\",  compose_brief_node)\n",
    "workflow.add_node(\"generate_music\", generate_music_node)\n",
    "workflow.add_node(\"mark_skipped\",   mark_skipped)\n",
    "\n",
    "workflow.add_edge(START, \"analyze_emotion\")\n",
    "workflow.add_edge(\"analyze_emotion\", \"compose_brief\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"compose_brief\",\n",
    "    should_generate,\n",
    "    {\"go\": \"generate_music\", \"skip\": \"mark_skipped\"}\n",
    ")\n",
    "workflow.add_edge(\"generate_music\", END)\n",
    "workflow.add_edge(\"mark_skipped\", END)\n",
    "\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51af93a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Emotion ===\n",
      "{'primary': '지루함', 'valence': -0.5, 'arousal': 0.3, 'confidence': 0.8, 'reasons': '페이지를 넘기는 손이 자주 멈췄고, 시간이 흐르는 게 잘 느껴지지 않았다는 점에서 지루함을 느꼈을 가능성이 높음.'}\n",
      "\n",
      "=== Music Brief ===\n",
      "{'mood': 'calm and reflective', 'bpm': 80, 'key': 'C minor', 'duration_sec': 150, 'instruments': ['warm piano', 'soft pad', 'gentle strings'], 'style_tags': ['calming', 'ambient', 'minimal', 'regulate:soothe'], 'prompt': 'A gentle piano with soft strings creates a serene atmosphere, inviting you to reflect and find peace amidst the stillness.'}\n",
      "\n",
      "=== Provider Used ===\n",
      "skipped\n",
      "\n",
      "=== Audio Path ===\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# === 9) 실행 예시 ===\n",
    "state = {\n",
    "    \"user_text\": \"일정을 정리하다가 페이지를 넘기는 손이 자주 멈췄다. 시간이 흐르는 게 잘 느껴지지 않았다.\"\n",
    "    # \"force_generate\": True  # ← 정말 생성할 때만 켜기 (크레딧 사용)\n",
    "}\n",
    "final = graph.invoke(state)\n",
    "\n",
    "def dump(obj):\n",
    "    return obj.model_dump() if hasattr(obj, \"model_dump\") else obj\n",
    "\n",
    "print(\"=== Emotion ===\")\n",
    "print(dump(final[\"emotion\"]))\n",
    "print(\"\\n=== Music Brief ===\")\n",
    "print(dump(final[\"brief\"]))\n",
    "print(\"\\n=== Provider Used ===\")\n",
    "print(final.get(\"provider_used\", \"skipped\"))\n",
    "print(\"\\n=== Audio Path ===\")\n",
    "print(final.get(\"audio_path\"))  # 생성 시에만 경로가 생김"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-env-e8JFwEVd-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
